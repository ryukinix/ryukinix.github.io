#+STARTUP: showall
#+STARTUP: hidestars
#+OPTIONS: H:2 num:nil tags:nil toc:nil timestamps:t todo:nil tasks:("IN-PROGRESS" "DONE")
#+LAYOUT: post
#+AUTHOR: Manoel Vilela
#+DATE: 2019-03-07 Thu 22:24
#+TITLE: Fundamentos de Estatística
#+DESCRIPTION: Revisão de Fundamentos de Estatística
#+TAGS: mathematics,datascience
#+CATEGORIES: mathematics

* Capítulo I: Modelagem Probabilística

Este capítulo refere-se como uma contextualização do uso prático de
probabilidade na engenharia.
** DONE Modelos Determinísticos
   CLOSED: [2017-09-11 Mon 09:30] SCHEDULED: <2017-09-10 Sun>

Modelos determinísticos tem a propriedade que não há fatores de
aleatoriedade no processo de modelagem da solução. Sua resposta sempre
se aproxima de maneira ótima para o problema e é previsível em
qualquer caso. Conhecidos modelos determinísticos são as análises da
física newtoniana, como dinâmica e cinemática. Conhecendo os valores
iniciais, é possível descrever a evolução de um sistema em condições
ideais.

Outro modelo conhecido por ser determinístico é o modelo matemático
envolvido nos circuitos elétricos. Como a lei de Ohm \(v = RI\).  Em
condições ideais, a resposta exata do sistema avaliado é descrito
pelas equações que regem o modelo.

É importante lembrar que um modelo matemático é comumente referenciado
como um sistema para descrever algo mensurável, que se assemelha a
algo real — como é o caso da física newtoniana e a teoria de circuitos
elétricos.

** DONE Modelos Probabilísticos
   CLOSED: [2017-09-11 Mon 10:07] SCHEDULED: <2017-09-10 Sun>

Muitos sistemas de interesse envolvem comportamentos imprevisíveis e
aleatórios. Esses sistemas não podem ser descritos com modelos
determinísticos, pois dependem de fatores
não-determinísticos. Experimentos aleatórios, como o fato de lançar
uma moeda, transmissão de pacotes, tempo de espera em uma fila... são
problemas com natureza aleatória. Não é possível modelar esse tipo de
problema com modelos determinísticos.

Nesse momento então surge um novo tipo de matemática que lidaremos
como Probabilidade e Estatística. No decorrer do livro, entraremos em
conceitos mais abstratos como o de /Random Processes/ (Processos
Estocásticos).

Os meios de comunicação da internet, assim como seus protocolos, são
bons exemplos de sistemas modelados com modelos probabilísticos. Não é
possível, por exemplo, saber de exato se um pacote ao ser enviado será
chegado ao destinatário. Temos uma probabilidade que isso ocorra e uma
determinada probabilidade relacionada a quantidade de vezes
necessárias que um pacote seja enviado até que ele tenha sucesso.

* Capítulo II: Fundamentação de Probabilidade

Conceitos básicos de probabilidade, axiomas, teoremas e implicações.


** DONE Axiomas
   CLOSED: [2017-09-11 Mon 10:40] SCHEDULED: <2017-09-10 Sun>

Seja \(P\) o operador de probabilidade, \(A\) e \(B\) eventos do
espaço amostral \(S\), é dado os seguintes axiomas no contexto de
probabilidade:

1. \(0 \leq P[A] \leq 1\)
2. \(P[S] = 1\)
3. Se A e B são eventos que não acontecem simultaneamente, então
   \(P[A \cup B] = P[A] + P[B]\)

Uma extensão do axioma 3 é para o caso que tenhamos um conjunto
enumerável de eventos que são mutuamente exclusivos, então a
probabilidade de todos eles é a soma das suas probabilidades
individuais.

Um colorário interessante é o da probabilidade complemento:

#+BEGIN_LATEX latex
\begin{equation}
P[A^c] =1 - P[A]
\end{equation}
#+END_LATEX

Usualmente a operação de complemento pode ser vista como a negação da
proposição que se avalia a probabilidade. Por exemplo: qual a
probabilidade de se jogar um dado e não aparecer o número 6? Ao
aplicar esse teorema o problema fica simples \(1 - \dfrac{1}{6}
\Rightarrow \dfrac{5}{6}\) dado que a probabilidade de aparecer
qualquer número em um dado é \(\dfrac{1}{6}\)

** DONE Eventos Independentes
   CLOSED: [2017-09-11 Mon 10:44] SCHEDULED: <2017-09-10 Sun>

Se dois eventos são independentes, como o ato de lançar duas moedas, a
intersecção de suas probabilidades devem ser igual ao produto das
probabilidades dos eventos.

#+BEGIN_LATEX latex
\begin{equation}
P(A \cap B) = P(A) \cdot P(B)
\end{equation}
#+END_LATEX

Um exemplo de eventos independentes é quando o estado anterior de um
evento ocorrido não interfere na probabilidade do próximo evento
ocorrer.  Por exemplo, duas moedas sendo lançadas ao mesmo tempo são
eventos independentes.  O que ocorrer em uma não depende de outra.

No entanto, por outro lado, a probabilidade de tirar uma carta \(X\)
num deque de 52 cartas sem reposição e tirar outra \(Y\) não são
eventos independentes.

** DONE Eventos Mutualmente Exclusivos
   CLOSED: [2017-09-11 Mon 10:45] SCHEDULED: <2017-09-11 Mon>

Se dois eventos \(A\) e \(B\) não podem ocorrer simultaneamente, então
temos duas propriedades:

#+BEGIN_LATEX latex
\begin{align}
P[A \cap B] &= 0 \\ P[A \cup B] &= P[A] + P[B]
\end{align}
#+END_LATEX

Isso se deve pelo tipo de experimento que ocorre. Em alguns casos, um
evento não pode ocorrer simultaneamente. Como o caso de um moeda ser
cara e coroa ao mesmo tempo, um carro ser verde e amarelo ao mesmo
tempo.  São eventos impossíveis, por isso a probabilidade é zero
(intuitivamente).  Muitas provas existem sobre esses colorários dos
axiomas da probabilidade, mas estão fora do escopo dessas notas — a
não ser quando for interessante demonstrar.

#+BEGIN_LATEX latex
\begin{align}
P[A \cup B] &= P[A] + P[B] - P[A \cap B]
\end{align}
#+END_LATEX


** DONE Probabilidade Condicional
   CLOSED: [2017-09-11 Mon 10:55] SCHEDULED: <2017-09-10 Sun>

A probabilidade condicional pode ser enxergada como uma nova base do
*espaço amostral* em cima de uma nova condição. É anunciado que \(P(A
\mid B)\) como: 'Probabilidade de A, dado que B já ocorreu'. Ou
simplesmente 'P de A dado B'.  A fórmula para seu cálculo é dado por:

#+BEGIN_LATEX latex
\begin{equation}
P[A \mid B] = \dfrac{P[A \cap B]}{P[B]}
\end{equation}
#+END_LATEX

Probabilidade condicional é usado quando estamos se referindo a
eventos dependentes. Um bom exemplo, como comentado anteriormente, é a
probabilidade de duas cartas escolhidas sequencialmente serem
advinhadas num deque de cartas.

** DONE Experimentos Sequenciais
   CLOSED: [2017-09-11 Mon 10:59] SCHEDULED: <2017-09-10 Sun>

Experimentos sequenciais nada mais são que eventos aplicados um depois
do outro.  Sua probabilidade depende se os eventos são dependentes ou
não. Para eventos independentes podemos aplicar simplesmente a regra
do produto, a probabilidade dos eventos ocorrerem é o produtório das
probabilidades desses eventos.

No entanto, se os eventos são dependentes, devemos ter mais cautela.

** DONE Probabilidade Binomial
   CLOSED: [2017-09-11 Mon 11:12] SCHEDULED: <2017-09-11 Mon>

A lei da probabilidade binomial descreve como a probabilidade de um
experimento evolui de acordo com o número de eventos sequenciais.

#+BEGIN_LATEX latex
\begin{equation}
p_n(k) = \binom{n}{k}p^k(n -p)^{n-k}
\end{equation}
#+END_LATEX

** DONE Teorema de Bayes
   CLOSED: [2017-09-11 Mon 10:01] SCHEDULED: <2017-09-10 Sun>
O teorema de Bayes, ou regra de Bayes, estabelece que o evento
condicional estão intrinsecamente ligados com a probabilidade do
evento em si ocorrer.  Isto é, a probabilidade condicional de A dado B
e B dado A, é proporcional as probabilidades de B e A.

#+BEGIN_LATEX latex
\begin{equation}
P(A \mid B) = \dfrac{P(B \mid A) P(A)}{P(B)}
\end{equation}
#+END_LATEX

Muito similar ao teorema da probabilidade condicional, o teorema de
Bayes geralmente tem sua formula descrita de forma mais sucinta
traduzindo a definição da probabilidade de \(P(A \cap \B)\) em termos
da probabilidade condicional.

Isto fica evidente quando lembramos que:

#+BEGIN_LATEX latex
\begin{equation}
P(A \cap B) = P(B \mid A)P(A) = P(A \mid B) P(B)
\end{equation}
#+END_LATEX


** DONE Teorema da Probabilidade Total
   CLOSED: [2017-09-11 Mon 11:18] SCHEDULED: <2017-09-10 Sun>

O teorema da probabilidade total referencia o teorema de Bayes com uma
especifica modelagem. Ele é enxergado com fatias do espaço amostral em
relação ao um evento de interesse. Logo, a probabilidade de um evento
\(A\) pode ser visto como a intersecção de todas essas parcelas de
eventos com nosso evento de interesse \(A\).


A partir disso tem-se que uma probabilidade qualquer \(A)\) pode ser
expressa em cima de:

#+BEGIN_LATEX latex
\begin{equation}
P[A] = \sum_{i=1}^n P[E_i \cap A] = \sum_{i=i}^n P[A \mid E_i] P[E_i]
\end{equation}
#+END_LATEX

** DONE Diagrama de Árvore
   CLOSED: [2017-09-11 Mon 09:54] SCHEDULED: <2017-09-10 Sun>

O diagrama de árvore é usado geralmente para descrever todos os
possíveis caminhos de um determinado experimento.  Como um modelo
probabilístico pode se comportar diante das variações de eventos.

Muito útil durante a análise, principalmente de eventos sequenciais,
para um caso avaliando dois lançamentos de moedas sequencias, tem-se a
seguinte possível arquitetura:

#+BEGIN_EXAMPLE
                                   _ / \
                               T H / \ / \
                            T H T H
#+END_EXAMPLE

Onde =T= significa /tail/ (coroa) e =H= /head/ (cara). Embora nesse
exemplo não pareça um tanto útil pois as probabilidades são iguais,
quando lidamos com sistemas com muitas peculiaridades, como
probabilidades condicionais pode ser bastante útil para
visualização. No entanto, é uma ferramenta visual para esclarecimento,
que pode ser muitas vezes ignorada.


* DONE Capitulo III: Variáveis aleatórias discretas
  CLOSED: [2017-09-26 ter 01:56] DEADLINE: <2017-09-14 Thu> SCHEDULED: <2017-09-12 Tue>

Bom, variáveis aleatórias discretas são definidas no contexto de
probabilidade e estatística. Uma variável aleatória nada mais é que
uma função que relaciona um evento (experimento aleatório) a um dado
número.

Para um variável aleatória ser definida, essa relação deve ser
conhecida.

Há muitos tipos de variáveis aleatórias, como variável de poison,
geométrica, bernoulli e a variável binomial. Cada uma delas são usadas
para casos distintos de problemas com natureza probabilística.

Nas próximas seções serão definidas, de uma maneira mais descritiva e
formal, as propriedades que uma variável aleatória discreta possuí.

Existe a noção de classe de eventos, que são uma coleção de
experimentos aleatório que possuí o mesmo tipo de experimento.
(como os resultados de lançar uma moeda ou um dado).

** DONE Probability Mass Function (PMF)
   CLOSED: [2017-09-24 dom 20:09]

A PMF, em português FMP, que significa função massa de probabilidade
se refere uma função de probabilidade que X assume dado valor. Sua
definição é bem tirada como pode ser visto a seguir:

#+BEGIN_LATEX latex
\begin{equation}
p_x(x) = P[X = x] = P[\{\zeta:X(\zeta) = x\}]
                    \qquad \text{for x a real number.}
\end{equation}
#+END_LATEX

Três axiomas são definidas para a PMF, dentre quais:

#+BEGIN_LATEX latex
\begin{align}
p_x(x) &\geq 0 &\text{for all x} \\
\sum_{k \in S_x} p_x(k) &= 1 \\
P[X \in B] &= \sum_{x \in B} p_x(x) &\text{where} \ B \subset S_X
\end{align}
#+END_LATEX

** DONE Distribuições
   CLOSED: [2017-09-24 dom 20:09]

Há varias tipos de distribuições para modelos de probabilidade. Cada
um desses modelos é aplicado para um determinado tipo de problema, a
seguir é comentado algum deles. Dessa maneira, uma determinada
distribuição está relacionado com uma definição de variável aleatória.

*** DONE Bernoulli
    CLOSED: [2017-09-24 dom 20:09]

Provavelmente uma das distribuições mais simples de todas, quando se
possui um problema de natureza binária, isto é, a variável aleatória
só pode assumir dois valores, então seu nome recebe como variável
aleatória de Bernoulli. Em casos, como um sistema que avalia
sucesso/falha de uma operação, é interessante usar Bernoulli. Por
exemplo \(X(E_{sucesso}) = 1\) e \(X(E_{falha}) = 0\).

*** DONE Geométrica
    CLOSED: [2017-09-24 dom 20:09]

Quando uma sequência de eventos é relacionada de forma independente
aos seus estados anteriores, essa variável é conhecida como Variável
Aleatória Geométrica. Sua forma é acontecer n eventos iguais sequencialmente,
até que o posto aconteça. É a única variável aleatória sem memória.
Um exemplo de uso dessa distribuição é a quantidade de pacotes necessários
que precisam ser enviados até que um deles chegue com sucesso.

#+BEGIN_LATEX latex
\begin{equation}
p_x(k) = P[X = k] = (1 - p)^{k-1}p = q^{k-1}p
\end{equation}
#+END_LATEX

*** DONE Binomial
    CLOSED: [2017-09-24 dom 20:09]

Semelhante ao caso da Geométrica, na binomial estamos interessados
nas possíveis combinações geradas entre os eventos. Por exemplo,
como é distribuída a probabilidade para eu obter n coroas no lançamento
de uma moeda k vezes?

A fórmula da binomial segue que:

#+BEGIN_LATEX latex
\begin{equation}
p_x(k) = P[X = k] = \binom{n}{k}p_k(1-p)^{n-k}
\end{equation}
#+END_LATEX

Outro exemplo interessante é contar a quantidade de erros numa
transmissão. Uma canal de comunicação binária introduz um bit de erro
em uma transmissão com probabilidade \(p\). Seja \(X\) o número de erros
em \(n\) independentes transmissões. Encontre a pmf de X. Encontre a
probabilidade de um ou mais erros.

A distribuição binomial é usada aqui pois pode ocorrer um erro em qualquer
uma das transmissões, embora a ordem que eles ocorreram não importam,
apenas que é possível ocorrer em qualquer das \(n\) transmissões.

Por exemplo, para \(P[X \leq 1]\) iremos somar a probabilidade de que
\(k = \{0, 1\}\).


*** DONE Poisson
    CLOSED: [2017-09-26 ter 01:55]

A variável de Poisson, uma variável discreta, é modelada
para descrever uma contagem num dado intervalo contínuo.
Ela é modelada através de uma função exponencial.

Um exemplo de uso para essa variável seria analisar quantas
pessoas chegam na estação de trem no intervalo de uma hora.

Define-se então a variável de Poisson como a seguir:

#+BEGIN_LATEX latex
\begin{equation}
P[N = k] = p_N(k) = \dfrac{\lambda^k e^{-\lambda}}{k!}
\end{equation}
#+END_LATEX


** DONE Valor esperado (Expected Value)
   CLOSED: [2017-09-24 dom 20:09]


O valor esperado ou média se refere a um valor de tendência numa distribuição
probabilística. Isto é, os valores mais prováveis de serem encontrados estão
em torno da média ou do valor esperado.

#+BEGIN_LATEX latex
\begin{equation}
E[X] = \sum_{x \in S_x} xp_x(x) = \sum_k x_k p_k(x_k)
\end{equation}
#+END_LATEX

Isto é, dado um subconjunto \(S_x\) do espaço amostral \(S\), sendo
esse subconjunto aqueles com os nossos eventos de interesse, a definição
de esperança define como a soma do produto dos individuais valores do conjunto
por sua probabilidade de ocorrer.

Para o valor esperado existir, é necessário que a soma convirja absolutamente.

** DONE Variância e Desvio Padrão
   CLOSED: [2017-09-24 dom 20:49]

A definição de variância em probabilidade estatística está relacionado
a amplitude que os valores oscilam em torno da média. Pode-se definir
de duas maneiras:

#+BEGIN_LATEX latex
\begin{equation}
\sigma_X^2 = VAR[X] = E[(X - m_x)^2] = E[X^2] - E[X]^2
\end{equation}
#+END_LATEX

Vale lembrar que a Esperança (E[X]) é um operador linear
que possuí as propriedades de superposição e homogeneidade.

O desvio padrão é denotado como a raiz quadrada da variança.
Sendo apenas \(\sigma_x\).

** DONE Momento de uma variável
   CLOSED: [2017-09-24 dom 20:49]

O momento é definido como uma propriedade referente ao valor
esperado de uma variável X. É definido como *n-ésimo momento de X*:
\(E[X^n]\).


** DONE PMF e Esperança Condicional
   CLOSED: [2017-10-23 Mon 01:09]

A PMF e Esperança condicional apenas estende os conceitos
previamente descritos com a Regra de Bayes e o Teorema da
Probabilidade Total.


* TODO Capítulo IV: Variáveis aleatórias contínuas
** TODO Cumulative Distribution Function (CDF)
  DEADLINE: <2017-09-14 Thu> SCHEDULED: <2017-09-12 Tue>
** TODO Probability Density Function (PDF)
** TODO The Expected Value of X
** TODO Distribuições Contínuas
** TODO Funções de uma variável aleatória
** TODO Inequações de Markov
** TODO Métodos de Transformada

* TODO Dúvidas

** TODO Há diferença entre Distribuição de Probabilidade e Variável Aleatória?
